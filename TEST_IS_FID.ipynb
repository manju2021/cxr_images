{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TEST_IS_FID.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manju2021/cxr_images/blob/master/TEST_IS_FID.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttCUpdczyN_2"
      },
      "source": [
        "# This Colab notebook first calculates the Inception Score of the training set of CIFAR-10,\n",
        "# then calculates the Fréchet Inception Distance between the training set and test set of CIFAR-10,\n",
        "# base on https://github.com/tsc2017/Inception-Score and https://github.com/tsc2017/Frechet-Inception-Distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RobUu_8WxAF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "d234184a-f0ce-49ba-96b4-426151d83b60"
      },
      "source": [
        "# Install TF-GAN\n",
        "!pip install tensorflow-gan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gan\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/2e/62922111d7d50e1900e3030764743ea7735540ce103b3ab30fd5cd2d8a2b/tensorflow_gan-2.0.0-py2.py3-none-any.whl (365kB)\n",
            "\r\u001b[K     |█                               | 10kB 15.2MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |██▊                             | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |████▌                           | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 81kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 307kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 317kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 327kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 337kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 348kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 358kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 368kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gan) (0.8.0)\n",
            "Requirement already satisfied: tensorflow-probability>=0.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gan) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub>=0.2->tensorflow-gan) (3.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub>=0.2->tensorflow-gan) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub>=0.2->tensorflow-gan) (1.18.5)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.7->tensorflow-gan) (0.3.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.7->tensorflow-gan) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.7->tensorflow-gan) (4.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-hub>=0.2->tensorflow-gan) (47.3.1)\n",
            "Installing collected packages: tensorflow-gan\n",
            "Successfully installed tensorflow-gan-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkiaBs_iXPS4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "65822ab3-90de-438b-8842-bb599b9746fd"
      },
      "source": [
        "# Download and extract the CIFAR-10 dataset\n",
        "! wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "! tar vxzf cifar-10-python.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-26 17:56:59--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz’\n",
            "\n",
            "\rcifar-10-python.tar   0%[                    ]       0  --.-KB/s               \rcifar-10-python.tar   2%[                    ]   4.30M  21.5MB/s               \rcifar-10-python.tar  16%[==>                 ]  26.16M  65.4MB/s               \rcifar-10-python.tar  29%[====>               ]  48.18M  80.3MB/s               \rcifar-10-python.tar  43%[=======>            ]  70.09M  87.6MB/s               \rcifar-10-python.tar  56%[==========>         ]  92.07M  92.0MB/s               \rcifar-10-python.tar  70%[=============>      ] 114.05M  95.0MB/s               \rcifar-10-python.tar  81%[===============>    ] 132.91M  94.9MB/s               \rcifar-10-python.tar  95%[==================> ] 154.58M  96.6MB/s               \rcifar-10-python.tar 100%[===================>] 162.60M  96.9MB/s    in 1.7s    \n",
            "\n",
            "2020-06-26 17:57:01 (96.9 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
            "\n",
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CIEQp6VXcp6"
      },
      "source": [
        "DATA_DIR='/content/cifar-10-batches-py'\n",
        "HEIGHT=WIDTH=32\n",
        "DATA_DIM=HEIGHT*WIDTH*3\n",
        "BATCH_SIZE=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSt3ADcVXJRx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0262edd-41a7-4045-dd77-221c55a47798"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4cuBoW_W1A-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "ee155610-9d67-47ac-ff2d-9da5b0b13de5"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jun 26 17:57:18 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K_oWd9KW-33"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import urllib\n",
        "import gzip\n",
        "import pickle\n",
        "\n",
        "def unpickle(file):\n",
        "    fo = open(file, 'rb')\n",
        "    dict = pickle.load(fo,encoding='latin1')\n",
        "    fo.close()\n",
        "    return dict['data'], dict['labels']\n",
        "\n",
        "def cifar_generator(filenames, batch_size, data_dir):\n",
        "    all_data = []\n",
        "    all_labels = []\n",
        "    for filename in filenames:        \n",
        "        data, labels = unpickle(data_dir + '/' + filename)\n",
        "        all_data.append(data)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "    images = np.concatenate(all_data, axis=0).reshape([-1,3,32,32]).transpose([0,2,3,1]).reshape([-1,32*32*3])\n",
        "    labels = np.concatenate(all_labels, axis=0)\n",
        "        \n",
        "    def get_epoch():\n",
        "        rng_state = np.random.get_state()\n",
        "        np.random.shuffle(images)\n",
        "        np.random.set_state(rng_state)\n",
        "        np.random.shuffle(labels)\n",
        "\n",
        "        for i in range(len(images) // batch_size):\n",
        "            yield (images[i*batch_size:(i+1)*batch_size], labels[i*batch_size:(i+1)*batch_size])\n",
        "\n",
        "    return get_epoch\n",
        "\n",
        "\n",
        "def load(batch_size, data_dir):\n",
        "    return (\n",
        "        cifar_generator(['data_batch_1','data_batch_2','data_batch_3','data_batch_4','data_batch_5'], batch_size, data_dir), \n",
        "        cifar_generator(['test_batch'], batch_size, data_dir)\n",
        "    )\n",
        "def inf_gen(MODE='TRAIN', BATCH_SIZE=BATCH_SIZE):\n",
        "  if MODE=='TRAIN':\n",
        "    train_gen, _ = load(BATCH_SIZE, data_dir=DATA_DIR)\n",
        "    while True:\n",
        "        for original_images, labels in train_gen():\n",
        "          yield 2./255*original_images-1,labels\n",
        "  elif MODE=='TEST':\n",
        "    _, test_gen = load(BATCH_SIZE, data_dir=DATA_DIR)\n",
        "    while True:\n",
        "        for original_images, labels in test_gen():\n",
        "          yield 2./255*original_images-1,labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS7Q6NPfeasK"
      },
      "source": [
        "train_gen=inf_gen('TRAIN')\n",
        "test_gen=inf_gen('TEST')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjqZKFKseXkt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PvksBYQZBqQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "7a632ec6-94aa-4caa-f472-5668508cfbc4"
      },
      "source": [
        "'''\n",
        "From https://github.com/tsc2017/Inception-Score\n",
        "Code derived from https://github.com/openai/improved-gan/blob/master/inception_score/model.py and https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py\n",
        "\n",
        "Usage:\n",
        "    Call get_inception_score(images, splits=10)\n",
        "Args:\n",
        "    images: A numpy array with values ranging from 0 to 255 and shape in the form [N, 3, HEIGHT, WIDTH] where N, HEIGHT and WIDTH can be arbitrary. A dtype of np.uint8 is recommended to save CPU memory.\n",
        "    splits: The number of splits of the images, default is 10.\n",
        "Returns:\n",
        "    Mean and standard deviation of the Inception Score across the splits.\n",
        "'''\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import os\n",
        "import functools\n",
        "import numpy as np\n",
        "import time\n",
        "from tensorflow.python.ops import array_ops\n",
        "# pip install tensorflow-gan\n",
        "import tensorflow_gan as tfgan\n",
        "session=tf.compat.v1.InteractiveSession()\n",
        "# A smaller BATCH_SIZE reduces GPU memory usage, but at the cost of a slight slowdown\n",
        "BATCH_SIZE = 50\n",
        "INCEPTION_TFHUB = 'https://tfhub.dev/tensorflow/tfgan/eval/inception/1'\n",
        "INCEPTION_OUTPUT = 'logits'\n",
        "\n",
        "# Run images through Inception.\n",
        "inception_images = tf.compat.v1.placeholder(tf.float32, [None, 3, None, None], name = 'inception_images')\n",
        "def inception_logits(images = inception_images, num_splits = 1):\n",
        "    images = tf.transpose(images, [0, 2, 3, 1])\n",
        "    size = 299\n",
        "    images = tf.compat.v1.image.resize_bilinear(images, [size, size])\n",
        "    generated_images_list = array_ops.split(images, num_or_size_splits = num_splits)\n",
        "    logits = tf.map_fn(\n",
        "        fn = tfgan.eval.classifier_fn_from_tfhub(INCEPTION_TFHUB, INCEPTION_OUTPUT, True),\n",
        "        elems = array_ops.stack(generated_images_list),\n",
        "        parallel_iterations = 8,\n",
        "        back_prop = False,\n",
        "        swap_memory = True,\n",
        "        name = 'RunClassifier')\n",
        "    logits = array_ops.concat(array_ops.unstack(logits), 0)\n",
        "    return logits\n",
        "\n",
        "logits=inception_logits()\n",
        "\n",
        "def get_inception_probs(inps):\n",
        "    session=tf.get_default_session()\n",
        "    n_batches = int(np.ceil(float(inps.shape[0]) / BATCH_SIZE))\n",
        "    preds = np.zeros([inps.shape[0], 1000], dtype = np.float32)\n",
        "    for i in range(n_batches):\n",
        "        inp = inps[i * BATCH_SIZE:(i + 1) * BATCH_SIZE] / 255. * 2 - 1\n",
        "        preds[i * BATCH_SIZE : i * BATCH_SIZE + min(BATCH_SIZE, inp.shape[0])] = session.run(logits,{inception_images: inp})[:, :1000]\n",
        "    preds = np.exp(preds) / np.sum(np.exp(preds), 1, keepdims=True)\n",
        "    return preds\n",
        "\n",
        "def preds2score(preds, splits=10):\n",
        "    scores = []\n",
        "    for i in range(splits):\n",
        "        part = preds[(i * preds.shape[0] // splits):((i + 1) * preds.shape[0] // splits), :]\n",
        "        kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))\n",
        "        kl = np.mean(np.sum(kl, 1))\n",
        "        scores.append(np.exp(kl))\n",
        "    return np.mean(scores), np.std(scores)\n",
        "\n",
        "def get_inception_score(images, splits=10):\n",
        "    assert(type(images) == np.ndarray)\n",
        "    assert(len(images.shape) == 4)\n",
        "    assert(images.shape[1] == 3)\n",
        "    assert(np.min(images[0]) >= 0 and np.max(images[0]) > 10), 'Image values should be in the range [0, 255]'\n",
        "    print('Calculating Inception Score with %i images in %i splits' % (images.shape[0], splits))\n",
        "    start_time=time.time()\n",
        "    preds = get_inception_probs(images)\n",
        "    mean, std = preds2score(preds, splits)\n",
        "    print('Inception Score calculation time: %f s' % (time.time() - start_time))\n",
        "    return mean, std  # Reference values: 11.38 for 50000 CIFAR-10 training set images, or mean=11.31, std=0.10 if in 10 splits."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:617: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Flatten instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:617: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Flatten instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPJ_klAZmaM1"
      },
      "source": [
        "def get_training_set_is(n=50000, splits=10):\n",
        "    all_samples = np.zeros([int(np.ceil(float(n)/BATCH_SIZE)*BATCH_SIZE),DATA_DIM],dtype=np.uint8)\n",
        "    for i in range(int(np.ceil(float(n)/BATCH_SIZE))):# inception score for num_batches of real data\n",
        "      all_samples[i*BATCH_SIZE:(i+1)*BATCH_SIZE]=((next(train_gen)[0]+1)/2*255).astype(np.uint8)\n",
        "    return get_inception_score(all_samples[:n].reshape([-1,HEIGHT,WIDTH,3]).transpose([0,3,1,2]), splits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UppqnvDYZZ2O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2884bd10-5416-422e-caab-12930e06f050"
      },
      "source": [
        "# Inception Score of the training set in 10 splits\n",
        "is_mean_and_std = get_training_set_is()\n",
        "print('Inception Score: mean=%f, std=%f'% is_mean_and_std)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Inception Score with 50000 images in 10 splits\n",
            "Inception Score calculation time: 468.586976 s\n",
            "Inception Score: mean=11.307608, std=0.089195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d09EnExikl_z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e68b02f8-1dbd-4f04-f7fe-c16e690f04bd"
      },
      "source": [
        "'''\n",
        "From https://github.com/tsc2017/Frechet-Inception-Distance\n",
        "Code derived from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py\n",
        "\n",
        "Usage:\n",
        "    Call get_fid(images1, images2)\n",
        "Args:\n",
        "    images1, images2: Numpy arrays with values ranging from 0 to 255 and shape in the form [N, 3, HEIGHT, WIDTH] where N, HEIGHT and WIDTH can be arbitrary. \n",
        "    dtype of the images is recommended to be np.uint8 to save CPU memory.\n",
        "Returns:\n",
        "    Frechet Inception Distance between the two image distributions.\n",
        "'''\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import os\n",
        "import functools\n",
        "import numpy as np\n",
        "import time\n",
        "from tensorflow.python.ops import array_ops\n",
        "# pip install tensorflow-gan\n",
        "import tensorflow_gan as tfgan\n",
        "\n",
        "session=tf.compat.v1.InteractiveSession()\n",
        "# A smaller BATCH_SIZE reduces GPU memory usage, but at the cost of a slight slowdown\n",
        "BATCH_SIZE = 50\n",
        "\n",
        "# Run images through Inception.\n",
        "inception_images = tf.compat.v1.placeholder(tf.float32, [None, 3, None, None], name = 'inception_images')\n",
        "activations1 = tf.compat.v1.placeholder(tf.float32, [None, None], name = 'activations1')\n",
        "activations2 = tf.compat.v1.placeholder(tf.float32, [None, None], name = 'activations2')\n",
        "fcd = tfgan.eval.frechet_classifier_distance_from_activations(activations1, activations2)\n",
        "\n",
        "INCEPTION_TFHUB = 'https://tfhub.dev/tensorflow/tfgan/eval/inception/1'\n",
        "INCEPTION_FINAL_POOL = 'pool_3'\n",
        "\n",
        "def inception_activations(images = inception_images, num_splits = 1):\n",
        "    images = tf.transpose(images, [0, 2, 3, 1])\n",
        "    size = 299\n",
        "    images = tf.compat.v1.image.resize_bilinear(images, [size, size])\n",
        "    generated_images_list = array_ops.split(images, num_or_size_splits = num_splits)\n",
        "    activations = tf.map_fn(\n",
        "        fn = tfgan.eval.classifier_fn_from_tfhub(INCEPTION_TFHUB, INCEPTION_FINAL_POOL, True),\n",
        "        elems = array_ops.stack(generated_images_list),\n",
        "        parallel_iterations = 1,\n",
        "        back_prop = False,\n",
        "        swap_memory = True,\n",
        "        name = 'RunClassifier')\n",
        "    activations = array_ops.concat(array_ops.unstack(activations), 0)\n",
        "    return activations\n",
        "\n",
        "activations =inception_activations()\n",
        "\n",
        "def get_inception_activations(inps):\n",
        "    n_batches = int(np.ceil(float(inps.shape[0]) / BATCH_SIZE))\n",
        "    act = np.zeros([inps.shape[0], 2048], dtype = np.float32)\n",
        "    for i in range(n_batches):\n",
        "        inp = inps[i * BATCH_SIZE : (i + 1) * BATCH_SIZE] / 255. * 2 - 1\n",
        "        act[i * BATCH_SIZE : i * BATCH_SIZE + min(BATCH_SIZE, inp.shape[0])] = session.run(activations, feed_dict = {inception_images: inp})\n",
        "    return act\n",
        "\n",
        "def activations2distance(act1, act2):\n",
        "    return session.run(fcd, feed_dict = {activations1: act1, activations2: act2})\n",
        "        \n",
        "def get_fid(images1, images2):\n",
        "    session=tf.get_default_session()\n",
        "    assert(type(images1) == np.ndarray)\n",
        "    assert(len(images1.shape) == 4)\n",
        "    assert(images1.shape[1] == 3)\n",
        "    assert(np.min(images1[0]) >= 0 and np.max(images1[0]) > 10), 'Image values should be in the range [0, 255]'\n",
        "    assert(type(images2) == np.ndarray)\n",
        "    assert(len(images2.shape) == 4)\n",
        "    assert(images2.shape[1] == 3)\n",
        "    assert(np.min(images2[0]) >= 0 and np.max(images2[0]) > 10), 'Image values should be in the range [0, 255]'\n",
        "    assert(images1.shape == images2.shape), 'The two numpy arrays must have the same shape'\n",
        "    print('Calculating FID with %i images from each distribution' % (images1.shape[0]))\n",
        "    start_time = time.time()\n",
        "    act1 = get_inception_activations(images1)\n",
        "    act2 = get_inception_activations(images2)\n",
        "    fid = activations2distance(act1, act2)\n",
        "    print('FID calculation time: %f s' % (time.time() - start_time))\n",
        "    return fid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1751: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHqBzSKDksyh"
      },
      "source": [
        "def train_test_sets_fid(n, gen1, gen2):\n",
        "    all_real_samples = np.zeros([n//BATCH_SIZE*BATCH_SIZE,DATA_DIM],dtype=np.uint8)\n",
        "    all_fake_samples = np.zeros([n//BATCH_SIZE*BATCH_SIZE,DATA_DIM],dtype=np.uint8)\n",
        "    for i in range(int(np.ceil(float(n)/BATCH_SIZE))):\n",
        "      all_real_samples[i*BATCH_SIZE:(i+1)*BATCH_SIZE]=((next(gen1)[0]+1)/2*255).astype(np.uint8)\n",
        "      all_fake_samples[i*BATCH_SIZE:(i+1)*BATCH_SIZE]=((next(gen2)[0]+1)/2*255).astype(np.uint8)\n",
        "    sample_size=min(all_fake_samples.shape[0],all_real_samples.shape[0])\n",
        "    return get_fid(all_real_samples[:sample_size].reshape([-1,HEIGHT,WIDTH,3]).transpose([0,3,1,2]),all_fake_samples[:sample_size].reshape([-1,HEIGHT,WIDTH,3]).transpose([0,3,1,2]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSUF_xIjl5_P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2540d894-df4a-4ede-8d1c-e44126c145a8"
      },
      "source": [
        "# FID between training set and test set\n",
        "_fid = train_test_sets_fid(50000, train_gen, test_gen)\n",
        "print('FID: %f'% _fid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating FID with 50000 images from each distribution\n",
            "FID calculation time: 933.986970 s\n",
            "FID: 3.153478\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}